{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing recursion limit of python\n",
    "import sys\n",
    "sys.setrecursionlimit(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.title = None\n",
    "        self.text = None\n",
    "\n",
    "        self.inlinks = []\n",
    "        self.outlinks = []\n",
    "\n",
    "        self.labels = []\n",
    "        self.label = None\n",
    "        self.keyword = None\n",
    "        self.tags = None\n",
    "        self.features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading NLP modules\n",
    "import nltk\n",
    "nltk.download(\"all\") \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "stoppers = set(stopwords.words('english'))\n",
    "for x in [c for c in 'abcdefghijklmnopqrstuvwxyz']:stoppers.add(x)\n",
    "\n",
    "# Processing words so that words they could be vectorized easily\n",
    "def process_text(text, lem=False):\n",
    "\n",
    "    wordnet=WordNetLemmatizer()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    corpus = []\n",
    "    for i in range(len(sentences)):\n",
    "        review = sentences[i]\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [word for word in review if not word in stoppers]\n",
    "        if lem:\n",
    "            review = [wordnet.lemmatize(word) for word in review]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)    \n",
    "\n",
    "    return corpus\n",
    "\n",
    "# Calculating TFIDF score of a corpus by treating each sentence as a document\n",
    "def tfidf(corpus):\n",
    "    cnt_list = [Counter(doc.split()) for doc in corpus]\n",
    "    tfidf_score = []\n",
    "\n",
    "    for doc in cnt_list:\n",
    "        if '.' in doc:\n",
    "            doc.pop('.')\n",
    "        s = sum([*doc.values()])\n",
    "        for word in doc:\n",
    "            tf = log(doc[word]/(s+1))\n",
    "            idf = log(len(corpus)/(1+sum((word in d) for d in cnt_list)))\n",
    "\n",
    "            tfidf_score.append([tf*idf, word])\n",
    "\n",
    "    return {word: score for word, score in sorted(tfidf_score)[::-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('graph.txt','rb') as file:\n",
    "    graph_dict = pickle.load(file)\n",
    "\n",
    "graph = [*graph_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for node in graph:\n",
    "    text = node.text\n",
    "    node.text = process_text(text)\n",
    "    node.keyword = tfidf(process_text(text))\n",
    "\n",
    "    # node.tags = tfidf(node.text, 5)\n",
    "    \n",
    "    if len(node.labels)>0:\n",
    "        temp = [0,0,0,0]\n",
    "        for x in node.labels:\n",
    "            temp[int(x)]+=1\n",
    "        node.labels = temp\n",
    "        node.label = temp.index(max(temp))\n",
    "    else:\n",
    "        node.label = None\n",
    "        node.labels = np.zeros(4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1.18164133370001: 'terms',\n",
       " -1.6620943476182115: 'expansion',\n",
       " -1.7778874154035074: 'expansion',\n",
       " -1.8770773617087897: 'terms',\n",
       " -1.9638338413573804: 'terms',\n",
       " -1.9839264708124529: 'expansion',\n",
       " -2.0992823467836748: 'products',\n",
       " -2.1733589754333065: 'expansion',\n",
       " -2.2455329753535485: 'products',\n",
       " -2.2845000312564268: 'expansion',\n",
       " -2.351102985779819: 'powers',\n",
       " -2.36328266740002: 'term',\n",
       " -2.6343572136354596: 'multiplied',\n",
       " -2.6831924662487343: 'sum',\n",
       " -2.69900011003203: 'polynomial',\n",
       " -2.745027162199949: 'products',\n",
       " -2.8178848839186164: 'sum',\n",
       " -2.9667616548783577: 'expanding',\n",
       " -2.975097229261034: 'multiplied',\n",
       " -3.1125960782457724: 'products',\n",
       " -3.324188695236423: 'also',\n",
       " -3.38581192303021: 'expression',\n",
       " -3.4446924766675435: 'obtained',\n",
       " -3.486602935836834: 'pascal',\n",
       " -3.5557748308070147: 'multiplication',\n",
       " -3.620846882437746: 'obtained',\n",
       " -3.65851029471775: 'coefficients',\n",
       " -3.7541547234175794: 'factors',\n",
       " -3.905949070844612: 'multiplied',\n",
       " -3.9276676827147607: 'coefficients',\n",
       " -3.9678529416249058: 'expanded',\n",
       " -4.2964515612536704: 'applied.',\n",
       " -4.346717950866613: 'equivalent',\n",
       " -4.376098427763839: 'subexpressions',\n",
       " -4.5690000625128535: 'also',\n",
       " -4.595772299322124: 'addition.',\n",
       " -4.7285559601738445: 'column',\n",
       " -4.852174590969823: 'ast',\n",
       " -4.928758969461308: 'one',\n",
       " -5.076436837556009: 'ascending',\n",
       " -5.6180514521008496: 'addition',\n",
       " -5.9053469136941725: 'binomial',\n",
       " -6.370328555575266: 'called'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph[4].keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {k:v for k,v in zip([*graph_dict.keys()], graph)}\n",
    "\n",
    "with open('editedGraph.txt','wb') as file:\n",
    "    pickle.dump(graph_dict, file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc2e62776262f8f078db2e2452279a7d5ccef75714a216a26c8e833b9ce92a2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
